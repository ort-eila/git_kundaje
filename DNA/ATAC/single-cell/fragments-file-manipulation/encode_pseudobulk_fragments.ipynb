{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the files are on Anvil / Terra workspace \n",
    "# please run it from the workspace analysis to avoid bucket access permission issues\n",
    "# or use the gcloud login auth interface to authenticate yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome, eila!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the methods from the notebook\n",
    "%run synapse_utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run tsv_files_utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO NEED TO CHANGE!\n",
    "bucket_id = \"fc-secure-0a879173-62d3-4c3a-8fc3-e35ee4248901\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file is available, nothing to copy\n"
     ]
    }
   ],
   "source": [
    "# read the proc.tsv object\n",
    "# Create a subset file of each rna_dataset and save it under the rna_dataset and call it {rna_dataset}_metadata.tsv\n",
    "\n",
    "# TODO: copy the metadata file for ENCODE datasets\n",
    "if os.path.exists(\"proc.tsv\") == False:\n",
    "    !gsutil cp 'gs://fc-secure-0a879173-62d3-4c3a-8fc3-e35ee4248901/ENCODE_synpase_annotation_mapping/proc.tsv' .\n",
    "else:\n",
    "    print(\"file is available, nothing to copy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names: ['cell_type_name,\"rna_dataset\",\"rna_library\",\"rna_barcode\",\"atac_dataset\",\"atac_library\",\"atac_barcode\",\"file\"']  type is <class 'list'>\n",
      "metadata_col_names after split is ['cell_type_name', '\"rna_dataset\"', '\"rna_library\"', '\"rna_barcode\"', '\"atac_dataset\"', '\"atac_library\"', '\"atac_barcode\"', '\"file\"']\n",
      "metadata_col_names after strip is ['cell_type_name', 'rna_dataset', 'rna_library', 'rna_barcode', 'atac_dataset', 'atac_library', 'atac_barcode', 'file']\n",
      "Column names after processing is: ['cell_type_name', 'rna_dataset', 'rna_library', 'rna_barcode', 'atac_dataset', 'atac_library', 'atac_barcode', 'file']  type is <class 'list'>\n",
      "column_atac_dataset_index is 4\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from itertools import islice\n",
    "import pandas as pd\n",
    "metadata_col_names = None\n",
    "df_relevant_rows = None\n",
    "\n",
    "# ENCODE metadata table\n",
    "filename = \"proc.tsv\"  # Replace with the path to your TSV file\n",
    "\n",
    "with open(filename, \"r\", newline=\"\") as tsvfile:\n",
    "    reader = csv.reader(tsvfile, delimiter=\"\\t\")  # Set delimiter as tab\n",
    "\n",
    "# Column names: ['cell_type_name,\"rna_dataset\",\"rna_library\",\"rna_barcode\",\"atac_dataset\",\"atac_library\",\"atac_barcode\",\"file\"']    # Read the header row\n",
    "    metadata_col_names = next(reader)\n",
    "    print(\"Column names:\", metadata_col_names,\" type is {}\".format(type(metadata_col_names)))\n",
    "    metadata_col_names = metadata_col_names[0].split(\",\")\n",
    "    print(\"metadata_col_names after split is {}\".format(metadata_col_names))\n",
    "    metadata_col_names = [x.strip('\"') for x in metadata_col_names]\n",
    "    print(\"metadata_col_names after strip is {}\".format(metadata_col_names))\n",
    "    print(\"Column names after processing is:\", metadata_col_names,\" type is {}\".format(type(metadata_col_names)))\n",
    "    column_atac_dataset_index = metadata_col_names.index(\"atac_dataset\")\n",
    "    print(\"column_atac_dataset_index is {}\".format(column_atac_dataset_index))\n",
    "\n",
    "    rows = []  # To store the extracted rows\n",
    "\n",
    "    # Debug: Read only the first 10 lines \n",
    "    # subset_rows = list(islice(reader, 10)) \n",
    "    # Process the data rows\n",
    "    # for row in subset_rows: # to do: comment\n",
    "    for row in reader: # to do: un-comment\n",
    "        # Process each row\n",
    "        # print(\"row is {}. type is {}. len is {}\".format(row,type(row),len(row)))\n",
    "        row = row[0].split(\",\")\n",
    "        row = [x.strip('\"') for x in row]\n",
    "        # print(\"row after processing is {}. type is {}. len is {}\".format(row,type(row),len(row)))\n",
    "        # print(\"column_rna_dataset_value is {}\".format(column_rna_dataset_value))\n",
    "        column_atac_dataset_value = row[column_atac_dataset_index]\n",
    "        # print(\"column_atac_dataset_value is {}\".format(column_atac_dataset_value))\n",
    "        \n",
    "        if column_atac_dataset_value != 'NA':\n",
    "            rows.append(row)\n",
    "            # print(\"adding row {}\".format(row))\n",
    "        else:\n",
    "            # print(\"Nothing to add: column_atac_dataset_value is {}\".format(column_atac_dataset_value))\n",
    "            continue\n",
    "    # Create a dataframe from the extracted rows\n",
    "    df_encode_rows = pd.DataFrame(rows, columns=metadata_col_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_type_name</th>\n",
       "      <th>rna_dataset</th>\n",
       "      <th>rna_library</th>\n",
       "      <th>rna_barcode</th>\n",
       "      <th>atac_dataset</th>\n",
       "      <th>atac_library</th>\n",
       "      <th>atac_barcode</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hepatocytes</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>ENCSR114OKU</td>\n",
       "      <td>ENCLB431YMH</td>\n",
       "      <td>GGAGGATCAAGCGGTA</td>\n",
       "      <td>EAID_000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hepatocytes</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>ENCSR114OKU</td>\n",
       "      <td>ENCLB431YMH</td>\n",
       "      <td>GTTACGATCGTGGTAT</td>\n",
       "      <td>EAID_000002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cell_type_name rna_dataset rna_library rna_barcode atac_dataset  \\\n",
       "0    Hepatocytes          NA          NA          NA  ENCSR114OKU   \n",
       "1    Hepatocytes          NA          NA          NA  ENCSR114OKU   \n",
       "\n",
       "  atac_library      atac_barcode         file  \n",
       "0  ENCLB431YMH  GGAGGATCAAGCGGTA  EAID_000002  \n",
       "1  ENCLB431YMH  GTTACGATCGTGGTAT  EAID_000002  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encode_rows.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1236715"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_encode_rows['atac_dataset'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsutil_ls_txt.txt\n"
     ]
    }
   ],
   "source": [
    "# gsutil_ls_txt.txt was generated with gsutils ls gs://path/to/fragmetn/files.tsv.gz\n",
    "!ls gsutil_ls_txt*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gs://fc-secure-0a879173-62d3-4c3a-8fc3-e35ee4248901/submissions/0e8c4f76-5f9f-4dc8-8ef3-608afb9395ab/share/38144a43-b98a-4c90-93ff-a7fbb88efd2f/call-atac/wf_atac/e7b3e84a-fea9-4fe6-ad7a-40af393fdb36/call-align/ENCSR987PQH.atac.filter.fragments.hg38.tsv.gz', 'gs://fc-secure-0a879173-62d3-4c3a-8fc3-e35ee4248901/submissions/8ef75ac6-1a49-4cbe-b61d-d62af4c904d7/share/24e3d191-38aa-4ed1-9255-dbfb14161097/call-atac/wf_atac/3d2abad2-1ff0-4477-a7a8-35aef31e2a3e/call-align/ENCSR618WVK.atac.filter.fragments.hg38.tsv.gz', 'gs://fc-secure-0a879173-62d3-4c3a-8fc3-e35ee4248901/submissions/97de835d-0f4e-474e-a583-987d6f6a4f2c/share/d8870ad0-1b10-454a-8c36-75350ea50cbb/call-atac/wf_atac/c53f4afa-8fd4-4995-93e1-7f4dee359afc/call-align/ENCSR023FME.atac.filter.fragments.hg38.tsv.gz', 'gs://fc-secure-0a879173-62d3-4c3a-8fc3-e35ee4248901/submissions/c467e890-b9f7-4458-a5b7-5581eb958cba/share/293acd9b-1e89-41d4-af76-247ca41af146/call-atac/wf_atac/2c759a0e-018b-4d6e-bbfc-257cbab95224/call-align/ENCSR868ZEI.atac.filter.fragments.hg38.tsv.gz', 'gs://fc-secure-0a879173-62d3-4c3a-8fc3-e35ee4248901/submissions/d5e8dc2b-9ba1-4bf5-8d2f-d277d4fcb9ea/share/93f6e99f-971e-4d44-bba1-c66858baf7f5/call-atac/wf_atac/e33d17e1-f030-42ab-aabb-1dc8397bd4b1/call-align/ENCSR058GOM.atac.filter.fragments.hg38.tsv.gz']\n"
     ]
    }
   ],
   "source": [
    "# LOAD the ls file from local - does not work on this machine\n",
    "def load_gs_ls_text_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        lines = [line.strip() for line in lines]\n",
    "    return lines\n",
    "\n",
    "# Example usage\n",
    "file_path = 'gsutil_ls_txt.txt'\n",
    "gs_path_to_search_sample_id = load_gs_ls_text_file(file_path)\n",
    "print(gs_path_to_search_sample_id[0:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_atac_dataset = [x.split(\"/\")[-1].split(\".\")[0] for x in gs_path_to_search_sample_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ENCSR114OKU', 'ENCSR114OKU', 'ENCSR114OKU']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atac_dataset_list = df_encode_rows[\"atac_dataset\"].tolist()\n",
    "atac_dataset_list[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ENCSR181XXQ',\n",
       " 'ENCSR845QFX',\n",
       " 'ENCSR023FME',\n",
       " 'ENCSR868ZEI',\n",
       " 'ENCSR397LYX',\n",
       " 'ENCSR660NEE']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# atac dataset in both\n",
    "atac_dataset_to_fragment = list(set(gs_atac_dataset) & set(atac_dataset_list))\n",
    "atac_dataset_to_fragment[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(atac_dataset_to_fragment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_type_name</th>\n",
       "      <th>rna_dataset</th>\n",
       "      <th>rna_library</th>\n",
       "      <th>rna_barcode</th>\n",
       "      <th>atac_dataset</th>\n",
       "      <th>atac_library</th>\n",
       "      <th>atac_barcode</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>510368</th>\n",
       "      <td>macrophage</td>\n",
       "      <td>ENCSR231FNL</td>\n",
       "      <td>ENCLB398IAZ</td>\n",
       "      <td>AAACCGCGTGACATAT</td>\n",
       "      <td>ENCSR987PQH</td>\n",
       "      <td>ENCLB714RNW</td>\n",
       "      <td>GTCACCATGAGCTATT</td>\n",
       "      <td>EAID_000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510369</th>\n",
       "      <td>cardiomyocyte</td>\n",
       "      <td>ENCSR231FNL</td>\n",
       "      <td>ENCLB398IAZ</td>\n",
       "      <td>AAACCGCGTTACATCC</td>\n",
       "      <td>ENCSR987PQH</td>\n",
       "      <td>ENCLB714RNW</td>\n",
       "      <td>ATGTTGTTGAGCTATT</td>\n",
       "      <td>EAID_000093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cell_type_name  rna_dataset  rna_library       rna_barcode  \\\n",
       "510368     macrophage  ENCSR231FNL  ENCLB398IAZ  AAACCGCGTGACATAT   \n",
       "510369  cardiomyocyte  ENCSR231FNL  ENCLB398IAZ  AAACCGCGTTACATCC   \n",
       "\n",
       "       atac_dataset atac_library      atac_barcode         file  \n",
       "510368  ENCSR987PQH  ENCLB714RNW  GTCACCATGAGCTATT  EAID_000093  \n",
       "510369  ENCSR987PQH  ENCLB714RNW  ATGTTGTTGAGCTATT  EAID_000093  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will check for which fragments do we have annotation data\n",
    "df_relevant_rows = df_encode_rows[df_encode_rows['atac_dataset'].isin(atac_dataset_to_fragment)]\n",
    "df_relevant_rows.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gs://fc-secure-0a879173-62d3-4c3a-8fc3-e35ee4248901/submissions/0e8c4f76-5f9f-4dc8-8ef3-608afb9395ab/share/38144a43-b98a-4c90-93ff-a7fbb88efd2f/call-atac/wf_atac/e7b3e84a-fea9-4fe6-ad7a-40af393fdb36/call-align/ENCSR987PQH.atac.filter.fragments.hg38.tsv.gz', 'gs://fc-secure-0a879173-62d3-4c3a-8fc3-e35ee4248901/submissions/97de835d-0f4e-474e-a583-987d6f6a4f2c/share/d8870ad0-1b10-454a-8c36-75350ea50cbb/call-atac/wf_atac/c53f4afa-8fd4-4995-93e1-7f4dee359afc/call-align/ENCSR023FME.atac.filter.fragments.hg38.tsv.gz', 'gs://fc-secure-0a879173-62d3-4c3a-8fc3-e35ee4248901/submissions/c467e890-b9f7-4458-a5b7-5581eb958cba/share/293acd9b-1e89-41d4-af76-247ca41af146/call-atac/wf_atac/2c759a0e-018b-4d6e-bbfc-257cbab95224/call-align/ENCSR868ZEI.atac.filter.fragments.hg38.tsv.gz', 'gs://fc-secure-0a879173-62d3-4c3a-8fc3-e35ee4248901/submissions/ff3a5809-0cd2-464c-8a29-9bf6311111ae/share/02c2df11-8d6c-4786-868a-94ecf3858bc5/call-atac/wf_atac/26b48087-2f17-469d-b3ff-b64720f9ddb4/call-align/ENCSR367GKP.atac.filter.fragments.hg38.tsv.gz']\n"
     ]
    }
   ],
   "source": [
    "gs_path_to_fragment = list(filter(lambda x: any(substring in x for substring in atac_dataset_to_fragment), gs_path_to_search_sample_id))\n",
    "print(gs_path_to_fragment[0:4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gs_path_to_fragment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://fc-secure-0a879173-62d3-4c3a-8fc3-e35ee4248901/submissions/0e8c4f76-5f9f-4dc8-8ef3-608afb9395ab/share/38144a43-b98a-4c90-93ff-a7fbb88efd2f/call-atac/wf_atac/e7b3e84a-fea9-4fe6-ad7a-40af393fdb36/call-align/ENCSR987PQH.atac.filter.fragments.hg38.tsv.gz'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_path_to_fragment[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # os.path.basename(\"gs://fc-secure-0a879173-62d3-4c3a-8fc3-e35ee4248901/submissions/0e8c4f76-5f9f-4dc8-8ef3-608afb9395ab/share/38144a43-b98a-4c90-93ff-a7fbb88efd2f/call-atac/wf_atac/e7b3e84a-fea9-4fe6-ad7a-40af393fdb36/call-align/ENCSR987PQH.atac.filter.fragments.hg38.tsv.gz\")\n",
    "# df_relevant_rows[df_relevant_rows['atac_dataset']=='ENCSR987PQH']['file'].to_list()[0]\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fragment_file is gs://fc-secure-0a879173-62d3-4c3a-8fc3-e35ee4248901/submissions/0e8c4f76-5f9f-4dc8-8ef3-608afb9395ab/share/38144a43-b98a-4c90-93ff-a7fbb88efd2f/call-atac/wf_atac/e7b3e84a-fea9-4fe6-ad7a-40af393fdb36/call-align/ENCSR987PQH.atac.filter.fragments.hg38.tsv.gz\n",
      "cur_atac_dataset is ENCSR987PQH\n",
      "folder_name in synpase is EAID_000093\n",
      "get_file_names parameters are: folder_id syn34271785 and current_depth 0\n",
      "current_depth is 0 \n",
      "folder_entities are <generator object Synapse.getChildren at 0x7fcdf05faab0> \n",
      "get_file_names parameters are: folder_id syn51246798 and current_depth 1\n",
      "current_depth is 1 \n",
      "folder_entities are <generator object Synapse.getChildren at 0x7fcdf05fab20> \n",
      "get_file_names parameters are: folder_id syn51246801 and current_depth 2\n",
      "folder_entities are <generator object Synapse.getChildren at 0x7fcdf05fac00>\n",
      "file_id is syn51246821\n",
      "label_file_synHandle is File: cell_types_l1.tsv.gz (syn51246821)\n",
      "  md5=65de9f16ff3b72b1034a7a60b32ea61f\n",
      "  fileSize=217160\n",
      "  contentType=text/tab-separated-values\n",
      "  externalURL=None\n",
      "  cacheDir=/users/eila/git_kundaje/DNA/ATAC/single-cell/fragments-file-manipulation/labels_syn51246821\n",
      "  files=['cell_types_l1.tsv.gz']\n",
      "  path=/users/eila/git_kundaje/DNA/ATAC/single-cell/fragments-file-manipulation/labels_syn51246821/cell_types_l1.tsv.gz\n",
      "  synapseStore=True\n",
      "properties:\n",
      "  concreteType=org.sagebionetworks.repo.model.FileEntity\n",
      "  createdBy=3454341\n",
      "  createdOn=2023-03-29T04:19:58.717Z\n",
      "  dataFileHandleId=123090394\n",
      "  etag=827bd1db-ee3f-4dfd-8692-9516a56e7df9\n",
      "  id=syn51246821\n",
      "  isLatestVersion=True\n",
      "  modifiedBy=3454341\n",
      "  modifiedOn=2023-04-05T15:47:54.528Z\n",
      "  name=cell_types_l1.tsv.gz\n",
      "  parentId=syn51246801\n",
      "  versionLabel=2\n",
      "  versionNumber=2\n",
      "annotations:\n",
      "\n",
      "full_labels_file_path is /users/eila/git_kundaje/DNA/ATAC/single-cell/fragments-file-manipulation/labels_syn51246821/cell_types_l1.tsv.gz\n",
      "df_labels head is                         cell_id   cell_type_id cell_type_name  \\\n",
      "0  ENCSR100UGC_AAACAGCCAATTAGGA  cardiomyocyte  cardiomyocyte   \n",
      "1  ENCSR100UGC_AAACAGCCACTTAACG  cardiomyocyte  cardiomyocyte   \n",
      "2  ENCSR100UGC_AAACCGAAGGGCTTTG  cardiomyocyte  cardiomyocyte   \n",
      "3  ENCSR100UGC_AAACCGAAGTCATTTC  cardiomyocyte  cardiomyocyte   \n",
      "4  ENCSR100UGC_AAACCGCGTGATTACG       neuronal       neuronal   \n",
      "\n",
      "   membership_score  \n",
      "0               NaN  \n",
      "1               NaN  \n",
      "2               NaN  \n",
      "3               NaN  \n",
      "4               NaN  \n",
      "group_id is cardiomyocyte\n",
      "file_name is /users/eila/git_kundaje/DNA/ATAC/single-cell/fragments-file-manipulation/ENCSR987PQH/cardiomyocyte/split_fragment_file_cardiomyocyte.tsv\n",
      "Split DataFrame for atac_dataset cardiomyocyte saved to /users/eila/git_kundaje/DNA/ATAC/single-cell/fragments-file-manipulation/ENCSR987PQH/cardiomyocyte/split_fragment_file_cardiomyocyte.tsv\n",
      "group_id is endocardial\n",
      "file_name is /users/eila/git_kundaje/DNA/ATAC/single-cell/fragments-file-manipulation/ENCSR987PQH/endocardial/split_fragment_file_endocardial.tsv\n",
      "Split DataFrame for atac_dataset endocardial saved to /users/eila/git_kundaje/DNA/ATAC/single-cell/fragments-file-manipulation/ENCSR987PQH/endocardial/split_fragment_file_endocardial.tsv\n",
      "group_id is endothelial_cell\n",
      "file_name is /users/eila/git_kundaje/DNA/ATAC/single-cell/fragments-file-manipulation/ENCSR987PQH/endothelial_cell/split_fragment_file_endothelial_cell.tsv\n",
      "Split DataFrame for atac_dataset endothelial_cell saved to /users/eila/git_kundaje/DNA/ATAC/single-cell/fragments-file-manipulation/ENCSR987PQH/endothelial_cell/split_fragment_file_endothelial_cell.tsv\n",
      "group_id is fibroblast\n",
      "file_name is /users/eila/git_kundaje/DNA/ATAC/single-cell/fragments-file-manipulation/ENCSR987PQH/fibroblast/split_fragment_file_fibroblast.tsv\n",
      "Split DataFrame for atac_dataset fibroblast saved to /users/eila/git_kundaje/DNA/ATAC/single-cell/fragments-file-manipulation/ENCSR987PQH/fibroblast/split_fragment_file_fibroblast.tsv\n",
      "group_id is lymphocyte\n",
      "file_name is /users/eila/git_kundaje/DNA/ATAC/single-cell/fragments-file-manipulation/ENCSR987PQH/lymphocyte/split_fragment_file_lymphocyte.tsv\n",
      "Split DataFrame for atac_dataset lymphocyte saved to /users/eila/git_kundaje/DNA/ATAC/single-cell/fragments-file-manipulation/ENCSR987PQH/lymphocyte/split_fragment_file_lymphocyte.tsv\n",
      "group_id is macrophage\n",
      "file_name is /users/eila/git_kundaje/DNA/ATAC/single-cell/fragments-file-manipulation/ENCSR987PQH/macrophage/split_fragment_file_macrophage.tsv\n",
      "Split DataFrame for atac_dataset macrophage saved to /users/eila/git_kundaje/DNA/ATAC/single-cell/fragments-file-manipulation/ENCSR987PQH/macrophage/split_fragment_file_macrophage.tsv\n",
      "group_id is mast_cell\n",
      "file_name is /users/eila/git_kundaje/DNA/ATAC/single-cell/fragments-file-manipulation/ENCSR987PQH/mast_cell/split_fragment_file_mast_cell.tsv\n",
      "Split DataFrame for atac_dataset mast_cell saved to /users/eila/git_kundaje/DNA/ATAC/single-cell/fragments-file-manipulation/ENCSR987PQH/mast_cell/split_fragment_file_mast_cell.tsv\n",
      "group_id is neuronal\n",
      "file_name is /users/eila/git_kundaje/DNA/ATAC/single-cell/fragments-file-manipulation/ENCSR987PQH/neuronal/split_fragment_file_neuronal.tsv\n",
      "Split DataFrame for atac_dataset neuronal saved to /users/eila/git_kundaje/DNA/ATAC/single-cell/fragments-file-manipulation/ENCSR987PQH/neuronal/split_fragment_file_neuronal.tsv\n",
      "group_id is pericyte\n",
      "file_name is /users/eila/git_kundaje/DNA/ATAC/single-cell/fragments-file-manipulation/ENCSR987PQH/pericyte/split_fragment_file_pericyte.tsv\n",
      "Split DataFrame for atac_dataset pericyte saved to /users/eila/git_kundaje/DNA/ATAC/single-cell/fragments-file-manipulation/ENCSR987PQH/pericyte/split_fragment_file_pericyte.tsv\n",
      "group_id is smooth_muscle_cell\n",
      "file_name is /users/eila/git_kundaje/DNA/ATAC/single-cell/fragments-file-manipulation/ENCSR987PQH/smooth_muscle_cell/split_fragment_file_smooth_muscle_cell.tsv\n",
      "Split DataFrame for atac_dataset smooth_muscle_cell saved to /users/eila/git_kundaje/DNA/ATAC/single-cell/fragments-file-manipulation/ENCSR987PQH/smooth_muscle_cell/split_fragment_file_smooth_muscle_cell.tsv\n",
      "\n",
      "\n",
      "local_files_created based on cell_type_id {'cardiomyocyte': '/users/eila/git_kundaje/DNA/ATAC/single-cell/fragments-file-manipulation/ENCSR987PQH/cardiomyocyte/split_fragment_file_cardiomyocyte.tsv', 'endocardial': '/users/eila/git_kundaje/DNA/ATAC/single-cell/fragments-file-manipulation/ENCSR987PQH/endocardial/split_fragment_file_endocardial.tsv', 'endothelial_cell': '/users/eila/git_kundaje/DNA/ATAC/single-cell/fragments-file-manipulation/ENCSR987PQH/endothelial_cell/split_fragment_file_endothelial_cell.tsv', 'fibroblast': '/users/eila/git_kundaje/DNA/ATAC/single-cell/fragments-file-manipulation/ENCSR987PQH/fibroblast/split_fragment_file_fibroblast.tsv', 'lymphocyte': '/users/eila/git_kundaje/DNA/ATAC/single-cell/fragments-file-manipulation/ENCSR987PQH/lymphocyte/split_fragment_file_lymphocyte.tsv', 'macrophage': '/users/eila/git_kundaje/DNA/ATAC/single-cell/fragments-file-manipulation/ENCSR987PQH/macrophage/split_fragment_file_macrophage.tsv', 'mast_cell': '/users/eila/git_kundaje/DNA/ATAC/single-cell/fragments-file-manipulation/ENCSR987PQH/mast_cell/split_fragment_file_mast_cell.tsv', 'neuronal': '/users/eila/git_kundaje/DNA/ATAC/single-cell/fragments-file-manipulation/ENCSR987PQH/neuronal/split_fragment_file_neuronal.tsv', 'pericyte': '/users/eila/git_kundaje/DNA/ATAC/single-cell/fragments-file-manipulation/ENCSR987PQH/pericyte/split_fragment_file_pericyte.tsv', 'smooth_muscle_cell': '/users/eila/git_kundaje/DNA/ATAC/single-cell/fragments-file-manipulation/ENCSR987PQH/smooth_muscle_cell/split_fragment_file_smooth_muscle_cell.tsv'}\n",
      "numer of cell_type_id is 10. cell_type_id_names is ['lymphocyte', 'fibroblast', 'neuronal', 'pericyte', 'smooth_muscle_cell', 'endothelial_cell', 'cardiomyocyte', 'macrophage', 'mast_cell', 'endocardial']\n",
      "label_cell_type_file_name is ENCSR987PQH_lymphocyte.tsv\n",
      "full_path_for_cell_type_id is /users/eila/git_kundaje/DNA/ATAC/single-cell/fragments-file-manipulation/ENCSR987PQH/lymphocyte/ENCSR987PQH_lymphocyte.tsv\n",
      "cell_type_df.head(2) is Empty DataFrame\n",
      "Columns: [chr, start_pos, end_pos, cell_id_atac_dataset, read_count, cell_id, atac_dataset, atac_dataset_cell_id]\n",
      "Index: []\n",
      "cells_barcodes[0:5] is []\n",
      " gs fragment_file is gs://fc-secure-0a879173-62d3-4c3a-8fc3-e35ee4248901/submissions/0e8c4f76-5f9f-4dc8-8ef3-608afb9395ab/share/38144a43-b98a-4c90-93ff-a7fbb88efd2f/call-atac/wf_atac/e7b3e84a-fea9-4fe6-ad7a-40af393fdb36/call-align/ENCSR987PQH.atac.filter.fragments.hg38.tsv.gz\n",
      "local_file_name is ENCSR987PQH.atac.filter.fragments.hg38.tsv.gz\n",
      "Nothing to copy. all files available\n",
      "read_tsv_gz_to_dataframe_skipping_comments_and_empty_lines_with_col_names for file is /users/eila/git_kundaje/DNA/ATAC/single-cell/fragments-file-manipulation/ENCSR987PQH.atac.filter.fragments.hg38.tsv.gz and column_names ['chr', 'start_pos', 'end_pos', 'cell_id_atac_dataset', 'read_count']\n",
      "df_fragments_file is     chr  start_pos  end_pos          cell_id_atac_dataset  read_count\n",
      "0  chr1      10006    10419  TCGGTTCTCATGTTTC_ENCSR987PQH           1\n",
      "1  chr1      10006    10431  CGTTGCGCAGGCTTCG_ENCSR987PQH           1\n",
      "2  chr1      10007    10241  CTGACCAAGTATTGGC_ENCSR987PQH           1\n",
      "3  chr1      10007    10401  ATTCATGAGGCCAATT_ENCSR987PQH           1\n",
      "4  chr1      10007    10407  AAGTTAGCAGACAAAC_ENCSR987PQH           1\n"
     ]
    }
   ],
   "source": [
    "# %run tsv_files_utils.ipynb\n",
    "\n",
    "# List of column names\n",
    "pipeline_column_names = ['dataset_id_cell_id', 'cell_type_id', 'gs_path','chromosome']\n",
    "# Initialize dataframe with column names\n",
    "df_pseudobulk_pipeline= pd.DataFrame(columns=pipeline_column_names)\n",
    "\n",
    "\n",
    "# Tanjin, here you decide how many samples to run\n",
    "# where you decide to run on samples [0:1] or more\n",
    "for fragment_file in gs_path_to_fragment[0:1]:\n",
    "    print(\"fragment_file is {}\".format(fragment_file))\n",
    "    # Step 1: split the labels file by cell_type_id. create tmp tsv files\n",
    "    # Step 2: Split the fragment file by the cell_bracodes that are avaiable\n",
    "    # Step 3: call the TagAlign for each of the fragmetns file\n",
    "    # Step 4: save the TSV file \n",
    "    # Step 5: write the created file to bucket\n",
    "    # Step 6: add a rows to the pipeline TSV table\n",
    "    cur_atac_dataset = fragment_file.split(\"/\")[-1].split(\".\")[0]\n",
    "    print(\"cur_atac_dataset is {}\".format(cur_atac_dataset))\n",
    "    \n",
    "    # Step 1: input: labels file. output: df of the subset by cell_type_id\n",
    "    # Step 1-1: get the labels file from synpase.\n",
    "    dataset_id = 'syn34271785'\n",
    "    folder_name = df_relevant_rows[df_relevant_rows['atac_dataset']==cur_atac_dataset]['file'].to_list()[0]\n",
    "    print(\"folder_name in synpase is {}\".format(folder_name))\n",
    "    # (starting_folder_id, first_subfolder_name, second_subfolder_name):\n",
    "    file_id_list = get_file_names_in_second_subfolder(dataset_id,folder_name,\"labels\")\n",
    "    file_id = file_id_list[0] # the label's file synID\n",
    "    print('file_id is {}'.format(file_id))\n",
    "    \n",
    "    # Download the synpase label file:\n",
    "    # Obtain a pointer and download the data to full_labels_file_path\n",
    "    label_file_synHandle = syn.get(entity=file_id) \n",
    "    print('label_file_synHandle is {}'.format(label_file_synHandle))\n",
    "    full_labels_file_path = label_file_synHandle.path\n",
    "    print('full_labels_file_path is {}'.format(full_labels_file_path))\n",
    "    \n",
    "    # Load the labels data to dataframe\n",
    "    df_labels = read_tsv_gz_to_dataframe_skipping_comments_and_empty_lines(full_labels_file_path)\n",
    "    print(\"df_labels head is {}\".format(df_labels.head()))\n",
    "    # df,fld_name,col_name,prefix_file_name)\n",
    "    split_files_dir = os.path.join(os.getcwd(),cur_atac_dataset)\n",
    "    local_files_created = split_df_based_on_col_name(df_labels,split_files_dir,\"cell_type_id\",cur_atac_dataset)\n",
    "    print(\"\\n\\nlocal_files_created based on cell_type_id {}\".format(local_files_created))\n",
    "\n",
    "    # Step 2: split the fragments files based on the files under the local_files_created\n",
    "    # loop on all the cell_type_id and create a fragment file that will be copied under the cell_type_id_folder\n",
    "    cell_type_id_names = os.listdir(split_files_dir)\n",
    "    print(\"numer of cell_type_id is {}. cell_type_id_names is {}\".format(len(cell_type_id_names),cell_type_id_names))\n",
    "\n",
    "    for cell_type_id in cell_type_id_names:\n",
    "        label_cell_type_file_name = os.listdir(os.path.join(split_files_dir,cell_type_id))\n",
    "        label_cell_type_file_name = label_cell_type_file_name[0]\n",
    "        print(\"label_cell_type_file_name is {}\".format(label_cell_type_file_name))\n",
    "        full_label_cell_type_file_name = os.path.join(split_files_dir,cell_type_id,label_cell_type_file_name)\n",
    "\n",
    "        # load the file for the cell_type_id into a dataframe and extract the cell_barcode \n",
    "        # the file name is from ls the folder\n",
    "        full_path_for_cell_type_id = os.path.join(split_files_dir,cell_type_id,label_cell_type_file_name)\n",
    "        print(\"full_path_for_cell_type_id is {}\".format(full_path_for_cell_type_id))\n",
    "        cell_type_df = read_tsv_file(full_path_for_cell_type_id)\n",
    "        print(\"cell_type_df.head(2) is {}\".format(cell_type_df.head()))\n",
    "        # get the cell barcode\n",
    "        cells_barcodes = cell_type_df['cell_id'].to_list()\n",
    "        print(\"cells_barcodes[0:5] is {}\".format(cells_barcodes[0:5]))\n",
    "\n",
    "        # Load the fragment file\n",
    "        print(\" gs fragment_file is {}\".format(fragment_file))\n",
    "        local_file_name = os.path.basename(fragment_file)\n",
    "        full_local_file_name = os.path.join(os.getcwd(),local_file_name)\n",
    "        print(\"local_file_name is {}\".format(local_file_name))\n",
    "        if (os.path.exists(local_file_name) == False):\n",
    "            !gsutil cp $fragment_file $local_file_name\n",
    "        else:\n",
    "            print(\"Nothing to copy. all files available\")\n",
    "        \n",
    "        # Define column names\n",
    "        column_names = ['chr', 'start_pos', 'end_pos', 'cell_id_atac_dataset' ,'read_count']\n",
    "        # file_path,column_names\n",
    "        # Tanjin, for any change / debug purpose: you can edit read_tsv_gz_to_dataframe_skipping_comments_and_empty_lines_with_col_names\n",
    "        # to load only 100 lines. This will shorten the execution time\n",
    "        # For any change in the utils file, make sure to execute %run tsv_files_utils.ipynb or %run synapse_utils.ipynb\n",
    "        print(\"read_tsv_gz_to_dataframe_skipping_comments_and_empty_lines_with_col_names for file is {} and column_names {}\".format(full_local_file_name,column_names))\n",
    "        df_fragments_file = read_tsv_gz_to_dataframe_skipping_comments_and_empty_lines_with_col_names(full_local_file_name,column_names)\n",
    "        print(\"df_fragments_file is {}\".format(df_fragments_file.head(5)))\n",
    "\n",
    "        # create all the options of cell_id and dataset_id that might be used to identify cell_id\n",
    "        # it is not always aligned with the fragment file cell_id\n",
    "        df_fragments_cell_id_and_atac_col_addition = split_column_to_cell_id_and_atac_dataset(df_fragments_file)\n",
    "        print(\"df_fragments_cell_id_and_atac_col_addition is {}\".format(df_fragments_cell_id_and_atac_col_addition.head(5)))\n",
    "\n",
    "        # Tanjin: potential issue.\n",
    "        # cell_id in the labels file can be a comnination of the atac_dataset_cell_id: ENCSR100UGC_ACCATTAAGCCGCAAC\n",
    "        # or cell_id_atac_dataset ACCATTAAGCCGCAAC_ENCSR100UGC or something else.\n",
    "        # all the combinations are ready in the df_fragments_cell_id_and_atac_col_addition\n",
    "        df_fragments_cell_type_id = filter_dataframe(df_fragments_cell_id_and_atac_col_addition,'atac_dataset_cell_id',cells_barcodes)\n",
    "        print(\"df_fragments_cell_type_id is {}\".format(df_fragments_cell_type_id))\n",
    "        # step 3: call tagAlign\n",
    "        df_tag_align = tag_align(df_fragments_cell_type_id)\n",
    "        print(\"df_tag_align.head() is {}\".format(df_tag_align.head()))\n",
    "        # Step 4: save the tagAlign file\n",
    "        tagAlign_file_name = \"{}_{}.tsv\".format(cur_atac_dataset,cell_type_id)\n",
    "        print(\"tagAlign_file_name is {}\".format(tagAlign_file_name))\n",
    "        full_path_cell_type_fragment_file = os.path.join(os.path.dirname(full_label_cell_type_file_name),tagAlign_file_name)\n",
    "        print(\"full_path_cell_type_fragment_file is {}\".format(full_path_cell_type_fragment_file))\n",
    "        df_tag_align.to_csv(full_path_cell_type_fragment_file, sep='\\t', index=False)\n",
    "\n",
    "        # Step 5: copy file to bucket - under the original fragment file\n",
    "        gs_dest = os.path.join(os.path.dirname(fragment_file),tagAlign_file_name)\n",
    "        print(\"copy tagAlign file {} to gcp  {}\".format(full_path_cell_type_fragment_file,gs_dest))\n",
    "        !gsutil -m cp $full_path_cell_type_fragment_file $gs_dest\n",
    "        \n",
    "        # Step 6: add a rows to the pipeline TSV table\n",
    "        # all fragment file cell_ids, cell_type_id, path_to_gs_file, chromosome\n",
    "        # chromosome_size_human - taken from the worskapce dashboard\n",
    "        gs_chrom_size_human = \"gs://broad-buenrostro-pipeline-genome-annotations/IGVF_human_v43/GRCh38_EBV.chrom.sizes.tsv\"\n",
    "\n",
    "        df_pseudobulk_pipeline = pd.concat([df_pseudobulk_pipeline, \\\n",
    "                                            pd.DataFrame({'dataset_id_cell_id': [tagAlign_file_name], \\\n",
    "                                                          'cell_type_id': [cell_type_id], \\\n",
    "                                                          'gs_path':[gs_dest], \\\n",
    "                                                          'chromosome': [gs_chrom_size_human]})], \\\n",
    "                                                          ignore_index=True)\n",
    "        \n",
    "        print(\"!!!!df_pseudobulk_pipeline is {} \".format(df_pseudobulk_pipeline))\n",
    "\n",
    "# save the pipeline input table\n",
    "df_pseudobulk_pipeline.to_csv(\"{}_pipeline_table.tsv\".format(cur_atac_dataset), sep='\\t', index=False)\n",
    "# # TODO: copy the GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
