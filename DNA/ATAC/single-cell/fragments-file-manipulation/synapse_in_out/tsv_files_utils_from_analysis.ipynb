{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5d6f330-aa2d-4325-91b0-8ee0919de81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "\n",
    "def read_tsv_gz_to_dataframe_skipping_comments_and_empty_lines(tsv_gz_file, comment_character='#'):\n",
    "    # Open the compressed file using gzip\n",
    "    print(\"tsv_gz_file is {}\".format(tsv_gz_file))\n",
    "    with gzip.open(tsv_gz_file, 'rt') as file:\n",
    "        # Skip comment lines and empty lines, and load the remaining data into a DataFrame\n",
    "        df = pd.read_csv(file, delimiter='\\t', comment=comment_character, skip_blank_lines=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# # # Specify the path to the TSV.gz file\n",
    "# tsv_gz_file = '/Users/eilaarich-landkof-stanford/Documents/Code/git_kundaje_genomics/DNA/ATAC/single-cell/fragments-file-manipulation/synapse_in_out/labels/syn34271785_ENCSR618WVK_syn34545542/cell_types.tsv.gz'\n",
    "\n",
    "# # # Read the TSV.gz file and create a DataFrame\n",
    "# dataframe = read_tsv_gz_to_dataframe_skipping_comments_and_empty_lines(tsv_gz_file)\n",
    "\n",
    "# # # Display the DataFrame\n",
    "# print(dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "060b8907-367b-46a5-99d1-b54f1ffb74bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "\n",
    "def read_tsv_gz_to_dataframe_skipping_empty_lines_and_rows(tsv_gz_file):\n",
    "    # Open the compressed file using gzip\n",
    "    print(\"tsv_gz_file is {}\".format(tsv_gz_file))\n",
    "    with gzip.open(tsv_gz_file, 'rt') as file:\n",
    "        # Skip comment lines and empty lines, and load the remaining data into a DataFrame\n",
    "        df = pd.read_csv(file, delimiter='\\t', skip_blank_lines=True,header=0,skiprows=6)\n",
    "\n",
    "    return df\n",
    "\n",
    "# # # Specify the path to the TSV.gz file\n",
    "# tsv_gz_file = '/Users/eilaarich-landkof-stanford/Documents/Code/git_kundaje_genomics/DNA/ATAC/single-cell/fragments-file-manipulation/synapse_in_out/labels/syn34271785_ENCSR618WVK_syn34545542/cell_types.tsv.gz'\n",
    "\n",
    "# # # Read the TSV.gz file and create a DataFrame\n",
    "# dataframe = read_tsv_gz_to_dataframe_skipping_comments_and_empty_lines_and_skip_rows(tsv_gz_file)\n",
    "\n",
    "# # # Display the DataFrame\n",
    "# print(dataframe.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39d916c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "\n",
    "def read_large_tsv_skip_comments_and_empty_lines(file_path, column_names):\n",
    "    chunk_size = 10000\n",
    "    chunks = pd.read_csv(\n",
    "        gzip.open(file_path, 'rt'),\n",
    "        sep='\\t',\n",
    "        chunksize=chunk_size,\n",
    "        comment='#',\n",
    "        skip_blank_lines=True,\n",
    "        names=column_names\n",
    "    )\n",
    "    dataframes = []\n",
    "\n",
    "    for chunk in chunks:\n",
    "        dataframes.append(chunk)\n",
    "\n",
    "    combined_df = pd.concat(dataframes)\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ba0a308-f4f4-45f5-b588-e34f88787f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "\n",
    "def read_tsv_gz_to_dataframe_skipping_comments_and_empty_lines_with_col_names(tsv_gz_file, col_names,comment_character='#'):\n",
    "    # debug only\n",
    "    # Specify the number of lines to read\n",
    "    n_lines = 1000\n",
    "\n",
    "    # Open the compressed file using gzip\n",
    "    with gzip.open(tsv_gz_file, 'rt') as file:\n",
    "        # Skip comment lines and empty lines, and load the remaining data into a DataFrame\n",
    "        df = pd.read_csv(file, delimiter='\\t', comment=comment_character, skip_blank_lines=True,names=col_names,nrows=n_lines)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48ffe24d-aafb-4231-a013-0175aa3fc426",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_column_to_cell_id_and_atac_dataset(df):\n",
    "    # Split 'Column2' into two columns\n",
    "    # df[['cell_id', 'atac_dataset']] = df['cell_id_atac_dataset'].str.split('_', 1, expand=True)\n",
    "    # Split column values by \"_\"\n",
    "    df[['cell_id', 'atac_dataset']] = df['cell_id_atac_dataset'].str.split('_', expand=True)\n",
    "    # Add a new column as a combination of 'atac_dataset' and 'cell_id'\n",
    "    df = df.assign(atac_dataset_cell_id=df['atac_dataset'] + '_' + df['cell_id'])\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf4a0f58-334f-4c28-a0aa-7077fdafd5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# prefix_file_name = split_fragment_file_ or \n",
    "def split_df_based_on_col_name(df,fld_name,col_name,prefix_file_name):\n",
    "    # Split the DataFrame based on unique ID values\n",
    "    split_dfs = {group_id: group for group_id, group in df.groupby(col_name)}\n",
    "    files_created = dict()\n",
    "    # Save each split DataFrame to separate files\n",
    "    for group_id, split_df in split_dfs.items():\n",
    "        print(\"group_id is {}\".format(group_id))\n",
    "        file_name = os.path.join(fld_name,group_id,\"{}_{}.tsv\".format(prefix_file_name,group_id))\n",
    "        print(\"file_name is {}\".format(file_name))\n",
    "#         unique file name based on folder id given and the split criteria\n",
    "        os.makedirs(os.path.join(fld_name,group_id),exist_ok=True)\n",
    "        files_created[group_id] = file_name # under the folder, will be used also for the other one\n",
    "        split_df.to_csv(file_name, sep='\\t', index=False)\n",
    "        print(f\"Split DataFrame for atac_dataset {group_id} saved to {file_name}\")\n",
    "    return(files_created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ed98371-0bf9-4a50-9409-f54083361845",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_proc_tsv(local_metadata_file_location):\n",
    "    import csv\n",
    "    from itertools import islice\n",
    "    import pandas as pd\n",
    "    metadata_col_names = None\n",
    "    df_relevant_rows = None\n",
    "    df_encode_rows=None\n",
    "    \n",
    "    with open(local_metadata_file_location, \"r\", newline=\"\") as tsvfile:\n",
    "        reader = csv.reader(tsvfile, delimiter=\"\\t\")  # Set delimiter as tab\n",
    "        # Column names: ['cell_type_name,\"rna_dataset\",\"rna_library\",\"rna_barcode\",\"atac_dataset\",\"atac_library\",\"atac_barcode\",\"file\"']    # Read the header row\n",
    "        metadata_col_names = next(reader)\n",
    "        print(\"Column names:\", metadata_col_names,\" type is {}\".format(type(metadata_col_names)))\n",
    "        metadata_col_names = metadata_col_names[0].split(\",\")\n",
    "        print(\"metadata_col_names after split is {}\".format(metadata_col_names))\n",
    "        metadata_col_names = [x.strip('\"') for x in metadata_col_names]\n",
    "        print(\"metadata_col_names after strip is {}\".format(metadata_col_names))\n",
    "        print(\"Column names after processing is:\", metadata_col_names,\" type is {}\".format(type(metadata_col_names)))\n",
    "        column_atac_dataset_index = metadata_col_names.index(\"atac_dataset\")\n",
    "        print(\"column_atac_dataset_index is {}\".format(column_atac_dataset_index))\n",
    "\n",
    "        rows = []  # To store the extracted rows\n",
    "        for row in reader: # to do: un-comment\n",
    "            # Process each row\n",
    "            # print(\"row is {}. type is {}. len is {}\".format(row,type(row),len(row)))\n",
    "            row = row[0].split(\",\")\n",
    "            row = [x.strip('\"') for x in row]\n",
    "            column_atac_dataset_value = row[column_atac_dataset_index]\n",
    "            \n",
    "            if column_atac_dataset_value != 'NA':\n",
    "                rows.append(row)\n",
    "                # print(\"adding row {}\".format(row))\n",
    "            else:\n",
    "                # print(\"Nothing to add: column_atac_dataset_value is {}\".format(column_atac_dataset_value))\n",
    "                continue\n",
    "        # Create a dataframe from the extracted rows\n",
    "        df_encode_rows = pd.DataFrame(rows, columns=metadata_col_names)\n",
    "        return(df_encode_rows)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a2f6f1c-638c-41c2-9043-e74522b6e946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_tsv_file(filepath):\n",
    "    df = pd.read_csv(filepath, sep='\\t')\n",
    "    return df\n",
    "\n",
    "# # Provide the filepath of the TSV file\n",
    "# tsv_filepath = '/path/to/file.tsv'\n",
    "\n",
    "# # Call the function to read the TSV file and return a dataframe\n",
    "# dataframe = read_tsv_file(tsv_filepath)\n",
    "\n",
    "# # Print the dataframe\n",
    "# print(dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e428b6d-0d9f-469c-afe1-bbf733710a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def filter_dataframe(df, column, values):\n",
    "    print(\"filter_dataframe column is {}\".format(column))\n",
    "#     print(\"filter_dataframe values is {}\".format(values))\n",
    "    filtered_df = df[df[column].isin(values)]\n",
    "    print(\"****filtered_df size is: \",filtered_df.shape)\n",
    "    \n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f85d9ec-d7a7-4093-a47d-5d6c2c4db87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tagAlign(df):\n",
    "    import pandas as pd\n",
    "    # converting fragments to tagalign format\n",
    "    rows = list()\n",
    "    # Define a custom order for the 'chr*' column\n",
    "    custom_order = ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', \\\n",
    "                   'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19',\n",
    "                   'chr20', 'chr21', 'chr22', 'chrx', 'chry','NaN']\n",
    "\n",
    "    for r in df.iterrows():\n",
    "        print(\" {}\".format(r))\n",
    "        row1 = []\n",
    "        row2 = []\n",
    "\n",
    "        row1.append(r[1][0])\n",
    "        row1.append(r[1][1])\n",
    "        row1.append(r[1][1] + 1)\n",
    "        row1.append(r[1][3])\n",
    "        row1.append('1')\n",
    "        row1.append('+')\n",
    "        # print(\"convert_to_tagAlign: row 1 is: {}\".format(row1))\n",
    "\n",
    "        row2.append(r[1][0])\n",
    "        row2.append(r[1][2] - 1)\n",
    "        row2.append(r[1][2])\n",
    "        row2.append(r[1][3])\n",
    "        row2.append('1')\n",
    "        row2.append('-')\n",
    "        # print(\"convert_to_tagAlign: row 2 is: {}\".format(row2))\n",
    "\n",
    "        rows.append(row1)\n",
    "        rows.append(row2)\n",
    "    \n",
    "    df_tag = pd.DataFrame(rows)\n",
    "    # Sort the DataFrame by the second column with the custom order and then by the first column\n",
    "    # Convert the 'choromosome' column to categorical with the custom order\n",
    "    # Convert column 1 to categorical with the custom order\n",
    "    df_tag[0] = pd.Categorical(df_tag[0], categories=custom_order, ordered=True)\n",
    "\n",
    "    # Sort the DataFrame by column 1 with the custom order and then by column 0\n",
    "    sorted_df = df_tag.sort_values(by=[0, 1])\n",
    "    print(\"convert_to_tagAlign: sorted_df is: {}\".format(sorted_df.head(10)))\n",
    "    \n",
    "    return sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b20c113e-ed52-4c06-8d81-19611e124f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tagAlign_unsorted(df):\n",
    "    import pandas as pd\n",
    "    # converting fragments to tagalign format\n",
    "    rows = list()\n",
    "#     # Define a custom order for the 'chr*' column\n",
    "#     custom_order = ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', \\\n",
    "#                    'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19',\n",
    "#                    'chr20', 'chr21', 'chr22', 'chrx', 'chry','NaN']\n",
    "\n",
    "    for r in df.iterrows():\n",
    "        print(\" {}\".format(r))\n",
    "        row1 = []\n",
    "        row2 = []\n",
    "\n",
    "        row1.append(r[1][0])\n",
    "        row1.append(r[1][1])\n",
    "        row1.append(r[1][1] + 1)\n",
    "        row1.append(r[1][3])\n",
    "        row1.append('1')\n",
    "        row1.append('+')\n",
    "        # print(\"convert_to_tagAlign: row 1 is: {}\".format(row1))\n",
    "\n",
    "        row2.append(r[1][0])\n",
    "        row2.append(r[1][2] - 1)\n",
    "        row2.append(r[1][2])\n",
    "        row2.append(r[1][3])\n",
    "        row2.append('1')\n",
    "        row2.append('-')\n",
    "        # print(\"convert_to_tagAlign: row 2 is: {}\".format(row2))\n",
    "\n",
    "        rows.append(row1)\n",
    "        rows.append(row2)\n",
    "    \n",
    "    df_tag = pd.DataFrame(rows)\n",
    "#     # Sort the DataFrame by the second column with the custom order and then by the first column\n",
    "#     # Convert the 'choromosome' column to categorical with the custom order\n",
    "#     # Convert column 1 to categorical with the custom order\n",
    "#     df_tag[0] = pd.Categorical(df_tag[0], categories=custom_order, ordered=True)\n",
    "\n",
    "#     # Sort the DataFrame by column 1 with the custom order and then by column 0\n",
    "#     sorted_df = df_tag.sort_values(by=[0, 1])\n",
    "#     print(\"convert_to_tagAlign: sorted_df is: {}\".format(sorted_df.head(10)))\n",
    "    \n",
    "    return df_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "957217b2-081a-4de2-8f52-f3cb4db3d66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For our purposes, a fragment line: \n",
    "\n",
    "# chr1    10006  10419 TCGGTTCTCATGTTTC_ENCSR987PQH         1\n",
    "\n",
    "# Corresponds to two tagalign lines:\n",
    "# chr1    10006  10007 TCGGTTCTCATGTTTC_ENCSR987PQH         1         +\n",
    "# chr1    10418  10419 TCGGTTCTCATGTTTC_ENCSR987PQH         1         -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "81daf2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_fragment_line_to_tagAlign(r):\n",
    "#     chr1\t10007\t10175\tENCSR023FME_GAAGGTTCAAAGTGTCAGTCAA\t1\n",
    "    rows_str = \"\"\n",
    "    r_list = r.split(\"\\t\")\n",
    "    # print(\"r_list fragment input is {}\".format(r_list))\n",
    "    row1 = []\n",
    "    row2 = []\n",
    "\n",
    "    row1.append(r_list[0])\n",
    "    row1.append(r_list[1])\n",
    "    row1.append(str(int(r_list[1]) + 1))\n",
    "    row1.append(r_list[3])\n",
    "    row1.append('1')\n",
    "    row1.append('+')\n",
    "    # print(\"convert_to_tagAlign: row 1 is: {}\".format(row1))\n",
    "\n",
    "    row2.append(r_list[0])\n",
    "    row2.append(str(int(r_list[2]) - 1))\n",
    "    row2.append(r_list[2])\n",
    "    row2.append(r_list[3])\n",
    "    row2.append('1')\n",
    "    row2.append('-')\n",
    "    # print(\"convert_to_tagAlign: row 2 is: {}\".format(row2))\n",
    "    \n",
    "    rows_str = \"\\t\".join(row1)+\"\\n\"+\"\\t\".join(row2)+\"\\n\"\n",
    "    # print(\"\\nrows_str output is {}\".format(rows_str))\n",
    "    return rows_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "895fa2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_fragment_line_string(string):\n",
    "    # Remove newline characters\n",
    "    string = string.replace(\"\\n\", \"\")\n",
    "\n",
    "    # Splitting by tab character\n",
    "    split_list = string.split(\"\\t\")\n",
    "\n",
    "    # Splitting the word before the last one by underscore\n",
    "    last_word = split_list[-2]\n",
    "    split_word = last_word.split(\"_\")\n",
    "\n",
    "    # Inserting the split word before the last one in the list\n",
    "    split_list.insert(-1, split_word[0])\n",
    "    split_list.insert(-1, split_word[1])\n",
    "\n",
    "    # Concatenating values at index 5 and index 4 with underscore\n",
    "    concatenated_value = split_list[5] + \"_\" + split_list[4]\n",
    "    split_list.append(concatenated_value)\n",
    "\n",
    "    return split_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7340bf-dc3f-42de-a0ed-0a4feedaaaab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8218f4cb-198f-457a-8296-c6368a97c0c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
