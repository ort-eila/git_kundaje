{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5d6f330-aa2d-4325-91b0-8ee0919de81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "\n",
    "def read_tsv_gz_to_dataframe_skipping_comments_and_empty_lines(tsv_gz_file, comment_character='#'):\n",
    "    # Open the compressed file using gzip\n",
    "    print(\"tsv_gz_file is {}\".format(tsv_gz_file))\n",
    "    with gzip.open(tsv_gz_file, 'rt') as file:\n",
    "        # Skip comment lines and empty lines, and load the remaining data into a DataFrame\n",
    "        df = pd.read_csv(file, delimiter='\\t', comment=comment_character, skip_blank_lines=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# # # Specify the path to the TSV.gz file\n",
    "# tsv_gz_file = '/Users/eilaarich-landkof-stanford/Documents/Code/git_kundaje_genomics/DNA/ATAC/single-cell/fragments-file-manipulation/synapse_in_out/labels/syn34271785_ENCSR618WVK_syn34545542/cell_types.tsv.gz'\n",
    "\n",
    "# # # Read the TSV.gz file and create a DataFrame\n",
    "# dataframe = read_tsv_gz_to_dataframe_skipping_comments_and_empty_lines(tsv_gz_file)\n",
    "\n",
    "# # # Display the DataFrame\n",
    "# print(dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "060b8907-367b-46a5-99d1-b54f1ffb74bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "\n",
    "def read_tsv_gz_to_dataframe_skipping_empty_lines_and_rows(tsv_gz_file,skiprows=6):\n",
    "    # Open the compressed file using gzip\n",
    "    print(\"tsv_gz_file is {}\".format(tsv_gz_file))\n",
    "    with gzip.open(tsv_gz_file, 'rt') as file:\n",
    "        # Skip comment lines and empty lines, and load the remaining data into a DataFrame\n",
    "        df = pd.read_csv(file, delimiter='\\t', skip_blank_lines=True,header=0,skiprows=skiprows)\n",
    "\n",
    "    return df\n",
    "\n",
    "# # # Specify the path to the TSV.gz file\n",
    "# tsv_gz_file = '/Users/eilaarich-landkof-stanford/Documents/Code/git_kundaje_genomics/DNA/ATAC/single-cell/fragments-file-manipulation/synapse_in_out/labels/syn34271785_ENCSR618WVK_syn34545542/cell_types.tsv.gz'\n",
    "\n",
    "# # # Read the TSV.gz file and create a DataFrame\n",
    "# dataframe = read_tsv_gz_to_dataframe_skipping_comments_and_empty_lines_and_skip_rows(tsv_gz_file)\n",
    "\n",
    "# # # Display the DataFrame\n",
    "# print(dataframe.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a69cff6-5a42-4b30-985e-c416963126e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cell_type_id</th>\n",
       "      <th>cell_type_name</th>\n",
       "      <th>membership_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENCSR398PIW-1_AAACGAAAGCCTCATA</td>\n",
       "      <td>Hepatocytes</td>\n",
       "      <td>Hepatocytes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENCSR398PIW-1_AAACGAAAGCTCCATA</td>\n",
       "      <td>Fibroblasts</td>\n",
       "      <td>Fibroblasts</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENCSR398PIW-1_AAACGAAAGTACTCGT</td>\n",
       "      <td>Hepatocytes</td>\n",
       "      <td>Hepatocytes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENCSR398PIW-1_AAACGAACACCCTATC</td>\n",
       "      <td>Hepatocytes</td>\n",
       "      <td>Hepatocytes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENCSR398PIW-1_AAACGCTCATGCGTGC</td>\n",
       "      <td>Hepatocytes</td>\n",
       "      <td>Hepatocytes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35564</th>\n",
       "      <td>ENCSR367YUX-1_ENCSR630YEA-1_TTTGTGTTCCTGATTT</td>\n",
       "      <td>Hepatocytes</td>\n",
       "      <td>Hepatocytes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35565</th>\n",
       "      <td>ENCSR367YUX-1_ENCSR630YEA-1_TTTGTGTTCTCCATAT</td>\n",
       "      <td>Hepatocytes</td>\n",
       "      <td>Hepatocytes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35566</th>\n",
       "      <td>ENCSR367YUX-1_ENCSR630YEA-1_TTTGTTGGTCTTGCAT</td>\n",
       "      <td>Fibroblasts</td>\n",
       "      <td>Fibroblasts</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35567</th>\n",
       "      <td>ENCSR367YUX-1_ENCSR630YEA-1_TTTGTTGGTTAATGAC</td>\n",
       "      <td>Hepatocytes</td>\n",
       "      <td>Hepatocytes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35568</th>\n",
       "      <td>ENCSR367YUX-1_ENCSR630YEA-1_TTTGTTGGTTTGGGTA</td>\n",
       "      <td>Hepatocytes</td>\n",
       "      <td>Hepatocytes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35569 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            cell_id cell_type_id  \\\n",
       "0                    ENCSR398PIW-1_AAACGAAAGCCTCATA  Hepatocytes   \n",
       "1                    ENCSR398PIW-1_AAACGAAAGCTCCATA  Fibroblasts   \n",
       "2                    ENCSR398PIW-1_AAACGAAAGTACTCGT  Hepatocytes   \n",
       "3                    ENCSR398PIW-1_AAACGAACACCCTATC  Hepatocytes   \n",
       "4                    ENCSR398PIW-1_AAACGCTCATGCGTGC  Hepatocytes   \n",
       "...                                             ...          ...   \n",
       "35564  ENCSR367YUX-1_ENCSR630YEA-1_TTTGTGTTCCTGATTT  Hepatocytes   \n",
       "35565  ENCSR367YUX-1_ENCSR630YEA-1_TTTGTGTTCTCCATAT  Hepatocytes   \n",
       "35566  ENCSR367YUX-1_ENCSR630YEA-1_TTTGTTGGTCTTGCAT  Fibroblasts   \n",
       "35567  ENCSR367YUX-1_ENCSR630YEA-1_TTTGTTGGTTAATGAC  Hepatocytes   \n",
       "35568  ENCSR367YUX-1_ENCSR630YEA-1_TTTGTTGGTTTGGGTA  Hepatocytes   \n",
       "\n",
       "      cell_type_name  membership_score  \n",
       "0        Hepatocytes               NaN  \n",
       "1        Fibroblasts               NaN  \n",
       "2        Hepatocytes               NaN  \n",
       "3        Hepatocytes               NaN  \n",
       "4        Hepatocytes               NaN  \n",
       "...              ...               ...  \n",
       "35564    Hepatocytes               NaN  \n",
       "35565    Hepatocytes               NaN  \n",
       "35566    Fibroblasts               NaN  \n",
       "35567    Hepatocytes               NaN  \n",
       "35568    Hepatocytes               NaN  \n",
       "\n",
       "[35569 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tsv_gz_file = \"/Users/eilaarich-landkof-stanford/Documents/Code/git_kundaje_genomics/DNA/ATAC/single-cell/fragments-file-manipulation/synapse_in_out/labels/syn34271785_ENCSR618WVK_syn34545411/cell_types.tsv.gz\"\n",
    "# skiprows=6\n",
    "# with gzip.open(tsv_gz_file, 'rt') as file:\n",
    "#   # Skip comment lines and empty lines, and load the remaining data into a DataFrame\n",
    "#   df = pd.read_csv(file, delimiter='\\t', skip_blank_lines=True,header=0,skiprows=skiprows)\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39d916c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "\n",
    "def read_large_tsv_skip_comments_and_empty_lines(file_path, column_names):\n",
    "    chunk_size = 10000\n",
    "    chunks = pd.read_csv(\n",
    "        gzip.open(file_path, 'rt'),\n",
    "        sep='\\t',\n",
    "        chunksize=chunk_size,\n",
    "        comment='#',\n",
    "        skip_blank_lines=True,\n",
    "        names=column_names\n",
    "    )\n",
    "    dataframes = []\n",
    "\n",
    "    for chunk in chunks:\n",
    "        dataframes.append(chunk)\n",
    "\n",
    "    combined_df = pd.concat(dataframes)\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ba0a308-f4f4-45f5-b588-e34f88787f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "\n",
    "def read_tsv_gz_to_dataframe_skipping_comments_and_empty_lines_with_col_names(tsv_gz_file, col_names,comment_character='#'):\n",
    "    # debug only\n",
    "    # Specify the number of lines to read\n",
    "    n_lines = 1000\n",
    "\n",
    "    # Open the compressed file using gzip\n",
    "    with gzip.open(tsv_gz_file, 'rt') as file:\n",
    "        # Skip comment lines and empty lines, and load the remaining data into a DataFrame\n",
    "        df = pd.read_csv(file, delimiter='\\t', comment=comment_character, skip_blank_lines=True,names=col_names,nrows=n_lines)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48ffe24d-aafb-4231-a013-0175aa3fc426",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_column_to_cell_id_and_atac_dataset(df):\n",
    "    # Split 'Column2' into two columns\n",
    "    # df[['cell_id', 'atac_dataset']] = df['cell_id_atac_dataset'].str.split('_', 1, expand=True)\n",
    "    # Split column values by \"_\"\n",
    "    df[['cell_id', 'atac_dataset']] = df['cell_id_atac_dataset'].str.split('_', expand=True)\n",
    "    # Add a new column as a combination of 'atac_dataset' and 'cell_id'\n",
    "    df = df.assign(atac_dataset_cell_id=df['atac_dataset'] + '_' + df['cell_id'])\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf4a0f58-334f-4c28-a0aa-7077fdafd5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# prefix_file_name = split_fragment_file_ or \n",
    "def split_df_based_on_col_name(df,fld_name,col_name,prefix_file_name):\n",
    "    # Split the DataFrame based on unique ID values\n",
    "    split_dfs = {group_id: group for group_id, group in df.groupby(col_name)}\n",
    "    files_created = dict()\n",
    "    # Save each split DataFrame to separate files\n",
    "    for group_id, split_df in split_dfs.items():\n",
    "        print(\"group_id is {}\".format(group_id))\n",
    "        file_name = os.path.join(fld_name,group_id,\"{}_{}.tsv\".format(prefix_file_name,group_id))\n",
    "        print(\"file_name is {}\".format(file_name))\n",
    "#         unique file name based on folder id given and the split criteria\n",
    "        os.makedirs(os.path.join(fld_name,group_id),exist_ok=True)\n",
    "        files_created[group_id] = file_name # under the folder, will be used also for the other one\n",
    "        split_df.to_csv(file_name, sep='\\t', index=False)\n",
    "        print(f\"Split DataFrame for atac_dataset {group_id} saved to {file_name}\")\n",
    "    return(files_created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ed98371-0bf9-4a50-9409-f54083361845",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_proc_tsv(local_metadata_file_location):\n",
    "    import csv\n",
    "    from itertools import islice\n",
    "    import pandas as pd\n",
    "    metadata_col_names = None\n",
    "    df_relevant_rows = None\n",
    "    df_encode_rows=None\n",
    "    \n",
    "    with open(local_metadata_file_location, \"r\", newline=\"\") as tsvfile:\n",
    "        reader = csv.reader(tsvfile, delimiter=\"\\t\")  # Set delimiter as tab\n",
    "        # Column names: ['cell_type_name,\"rna_dataset\",\"rna_library\",\"rna_barcode\",\"atac_dataset\",\"atac_library\",\"atac_barcode\",\"file\"']    # Read the header row\n",
    "        metadata_col_names = next(reader)\n",
    "        print(\"Column names:\", metadata_col_names,\" type is {}\".format(type(metadata_col_names)))\n",
    "        metadata_col_names = metadata_col_names[0].split(\",\")\n",
    "        print(\"metadata_col_names after split is {}\".format(metadata_col_names))\n",
    "        metadata_col_names = [x.strip('\"') for x in metadata_col_names]\n",
    "        print(\"metadata_col_names after strip is {}\".format(metadata_col_names))\n",
    "        print(\"Column names after processing is:\", metadata_col_names,\" type is {}\".format(type(metadata_col_names)))\n",
    "        column_atac_dataset_index = metadata_col_names.index(\"atac_dataset\")\n",
    "        print(\"column_atac_dataset_index is {}\".format(column_atac_dataset_index))\n",
    "\n",
    "        rows = []  # To store the extracted rows\n",
    "        for row in reader: # to do: un-comment\n",
    "            # Process each row\n",
    "            # print(\"row is {}. type is {}. len is {}\".format(row,type(row),len(row)))\n",
    "            row = row[0].split(\",\")\n",
    "            row = [x.strip('\"') for x in row]\n",
    "            column_atac_dataset_value = row[column_atac_dataset_index]\n",
    "            \n",
    "            if column_atac_dataset_value != 'NA':\n",
    "                rows.append(row)\n",
    "                # print(\"adding row {}\".format(row))\n",
    "            else:\n",
    "                # print(\"Nothing to add: column_atac_dataset_value is {}\".format(column_atac_dataset_value))\n",
    "                continue\n",
    "        # Create a dataframe from the extracted rows\n",
    "        df_encode_rows = pd.DataFrame(rows, columns=metadata_col_names)\n",
    "        return(df_encode_rows)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a2f6f1c-638c-41c2-9043-e74522b6e946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_tsv_file(filepath):\n",
    "    df = pd.read_csv(filepath, sep='\\t')\n",
    "    return df\n",
    "\n",
    "# # Provide the filepath of the TSV file\n",
    "# tsv_filepath = '/path/to/file.tsv'\n",
    "\n",
    "# # Call the function to read the TSV file and return a dataframe\n",
    "# dataframe = read_tsv_file(tsv_filepath)\n",
    "\n",
    "# # Print the dataframe\n",
    "# print(dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69dfe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_tsv_file_no_index(filepath):\n",
    "    df = pd.read_csv(filepath, sep='\\t',index_col=None)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e428b6d-0d9f-469c-afe1-bbf733710a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def filter_dataframe(df, column, values):\n",
    "    print(\"filter_dataframe column is {}\".format(column))\n",
    "#     print(\"filter_dataframe values is {}\".format(values))\n",
    "    filtered_df = df[df[column].isin(values)]\n",
    "    print(\"****filtered_df size is: \",filtered_df.shape)\n",
    "    \n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f85d9ec-d7a7-4093-a47d-5d6c2c4db87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tagAlign(df):\n",
    "    import pandas as pd\n",
    "    # converting fragments to tagalign format\n",
    "    rows = list()\n",
    "    # Define a custom order for the 'chr*' column\n",
    "    custom_order = ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', \\\n",
    "                   'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19',\n",
    "                   'chr20', 'chr21', 'chr22', 'chrx', 'chry','NaN']\n",
    "\n",
    "    for r in df.iterrows():\n",
    "        print(\" {}\".format(r))\n",
    "        row1 = []\n",
    "        row2 = []\n",
    "\n",
    "        row1.append(r[1][0])\n",
    "        row1.append(r[1][1])\n",
    "        row1.append(r[1][1] + 1)\n",
    "        row1.append(r[1][3])\n",
    "        row1.append('1')\n",
    "        row1.append('+')\n",
    "        # print(\"convert_to_tagAlign: row 1 is: {}\".format(row1))\n",
    "\n",
    "        row2.append(r[1][0])\n",
    "        row2.append(r[1][2] - 1)\n",
    "        row2.append(r[1][2])\n",
    "        row2.append(r[1][3])\n",
    "        row2.append('1')\n",
    "        row2.append('-')\n",
    "        # print(\"convert_to_tagAlign: row 2 is: {}\".format(row2))\n",
    "\n",
    "        rows.append(row1)\n",
    "        rows.append(row2)\n",
    "    \n",
    "    df_tag = pd.DataFrame(rows)\n",
    "    # Sort the DataFrame by the second column with the custom order and then by the first column\n",
    "    # Convert the 'choromosome' column to categorical with the custom order\n",
    "    # Convert column 1 to categorical with the custom order\n",
    "    df_tag[0] = pd.Categorical(df_tag[0], categories=custom_order, ordered=True)\n",
    "\n",
    "    # Sort the DataFrame by column 1 with the custom order and then by column 0\n",
    "    sorted_df = df_tag.sort_values(by=[0, 1])\n",
    "    print(\"convert_to_tagAlign: sorted_df is: {}\".format(sorted_df.head(10)))\n",
    "    \n",
    "    return sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b20c113e-ed52-4c06-8d81-19611e124f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tagAlign_unsorted(df):\n",
    "    import pandas as pd\n",
    "    # converting fragments to tagalign format\n",
    "    rows = list()\n",
    "#     # Define a custom order for the 'chr*' column\n",
    "#     custom_order = ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', \\\n",
    "#                    'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19',\n",
    "#                    'chr20', 'chr21', 'chr22', 'chrx', 'chry','NaN']\n",
    "\n",
    "    for r in df.iterrows():\n",
    "        print(\" {}\".format(r))\n",
    "        row1 = []\n",
    "        row2 = []\n",
    "\n",
    "        row1.append(r[1][0])\n",
    "        row1.append(r[1][1])\n",
    "        row1.append(r[1][1] + 1)\n",
    "        row1.append(r[1][3])\n",
    "        row1.append('1')\n",
    "        row1.append('+')\n",
    "        # print(\"convert_to_tagAlign: row 1 is: {}\".format(row1))\n",
    "\n",
    "        row2.append(r[1][0])\n",
    "        row2.append(r[1][2] - 1)\n",
    "        row2.append(r[1][2])\n",
    "        row2.append(r[1][3])\n",
    "        row2.append('1')\n",
    "        row2.append('-')\n",
    "        # print(\"convert_to_tagAlign: row 2 is: {}\".format(row2))\n",
    "\n",
    "        rows.append(row1)\n",
    "        rows.append(row2)\n",
    "    \n",
    "    df_tag = pd.DataFrame(rows)\n",
    "#     # Sort the DataFrame by the second column with the custom order and then by the first column\n",
    "#     # Convert the 'choromosome' column to categorical with the custom order\n",
    "#     # Convert column 1 to categorical with the custom order\n",
    "#     df_tag[0] = pd.Categorical(df_tag[0], categories=custom_order, ordered=True)\n",
    "\n",
    "#     # Sort the DataFrame by column 1 with the custom order and then by column 0\n",
    "#     sorted_df = df_tag.sort_values(by=[0, 1])\n",
    "#     print(\"convert_to_tagAlign: sorted_df is: {}\".format(sorted_df.head(10)))\n",
    "    \n",
    "    return df_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "957217b2-081a-4de2-8f52-f3cb4db3d66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For our purposes, a fragment line: \n",
    "\n",
    "# chr1    10006  10419 TCGGTTCTCATGTTTC_ENCSR987PQH         1\n",
    "\n",
    "# Corresponds to two tagalign lines:\n",
    "# chr1    10006  10007 TCGGTTCTCATGTTTC_ENCSR987PQH         1         +\n",
    "# chr1    10418  10419 TCGGTTCTCATGTTTC_ENCSR987PQH         1         -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "81daf2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_fragment_line_to_tagAlign(r):\n",
    "#     chr1\t10007\t10175\tENCSR023FME_GAAGGTTCAAAGTGTCAGTCAA\t1\n",
    "    rows_str = \"\"\n",
    "    r_list = r.split(\"\\t\")\n",
    "    # print(\"r_list fragment input is {}\".format(r_list))\n",
    "    row1 = []\n",
    "    row2 = []\n",
    "\n",
    "    row1.append(r_list[0])\n",
    "    row1.append(r_list[1])\n",
    "    row1.append(str(int(r_list[1]) + 1))\n",
    "    row1.append(r_list[3])\n",
    "    row1.append('1')\n",
    "    row1.append('+')\n",
    "    # print(\"convert_to_tagAlign: row 1 is: {}\".format(row1))\n",
    "\n",
    "    row2.append(r_list[0])\n",
    "    row2.append(str(int(r_list[2]) - 1))\n",
    "    row2.append(r_list[2])\n",
    "    row2.append(r_list[3])\n",
    "    row2.append('1')\n",
    "    row2.append('-')\n",
    "    # print(\"convert_to_tagAlign: row 2 is: {}\".format(row2))\n",
    "    \n",
    "    rows_str = \"\\t\".join(row1)+\"\\n\"+\"\\t\".join(row2)+\"\\n\"\n",
    "    # print(\"\\nrows_str output is {}\".format(rows_str))\n",
    "    return rows_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "895fa2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_fragment_line_string(string):\n",
    "    # Remove newline characters\n",
    "    string = string.replace(\"\\n\", \"\")\n",
    "    # print(\"split_fragment_line_string: string after remove new line\",string)\n",
    "    # Splitting by tab character\n",
    "    split_list = string.split(\"\\t\")\n",
    "    # print(\"split_fragment_line_string: split_list \",split_list)\n",
    "    # Splitting the word before the last one by underscore\n",
    "    last_word = split_list[-2]\n",
    "    if (\"_\" in last_word):\n",
    "        # print(\"split_fragment_line_string: last_word \",last_word)\n",
    "        split_word = last_word.split(\"_\")\n",
    "        # print(\"split_fragment_line_string: split_word \",split_word)\n",
    "        # Inserting the split word before the last one in the list\n",
    "        split_list.insert(-1, split_word[0].strip())\n",
    "        # print(\"split_fragment_line_string: split_list insert \",split_list)\n",
    "        split_list.insert(-1, split_word[1].strip())\n",
    "        # print(\"split_fragment_line_string: split_list insert 2 \",split_list)\n",
    "\n",
    "        # Concatenating values at index 5 and index 4 with underscore\n",
    "        concatenated_value = split_list[5].strip() + \"_\" + split_list[4].strip()\n",
    "        # print(\"split_fragment_line_string: concatenated_value  \",concatenated_value)\n",
    "        split_list.append(concatenated_value)\n",
    "        # print(\"split_fragment_line_string: split_list appbend \",split_list)\n",
    "\n",
    "        concatenated_value_2 = split_list[4] +\"_\" + split_list[5]\n",
    "        # print(\"split_fragment_line_string: concatenated_value2  \",concatenated_value_2)\n",
    "        split_list.append(concatenated_value_2)\n",
    "        # # print(\"split_fragment_line_string: split_list appbend \",split_list)\n",
    "    \n",
    "    return split_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d8e2da6-de43-42a9-b732-86bbb0cbc2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_fragment_line_string: string after remove new line chr1\t10005\t10406\tAAAGGCTCACCAGGTT_ENCSR618WVK\t1\n",
      "split_fragment_line_string: split_list  ['chr1', '10005', '10406', 'AAAGGCTCACCAGGTT_ENCSR618WVK', '1']\n",
      "split_fragment_line_string: last_word  AAAGGCTCACCAGGTT_ENCSR618WVK\n",
      "split_fragment_line_string: split_word  ['AAAGGCTCACCAGGTT', 'ENCSR618WVK']\n",
      "split_fragment_line_string: split_list insert  ['chr1', '10005', '10406', 'AAAGGCTCACCAGGTT_ENCSR618WVK', 'AAAGGCTCACCAGGTT', '1']\n",
      "split_fragment_line_string: split_list insert 2  ['chr1', '10005', '10406', 'AAAGGCTCACCAGGTT_ENCSR618WVK', 'AAAGGCTCACCAGGTT', 'ENCSR618WVK', '1']\n",
      "split_fragment_line_string: concatenated_value   ENCSR618WVK_AAAGGCTCACCAGGTT\n",
      "split_fragment_line_string: split_list appbend  ['chr1', '10005', '10406', 'AAAGGCTCACCAGGTT_ENCSR618WVK', 'AAAGGCTCACCAGGTT', 'ENCSR618WVK', '1', 'ENCSR618WVK_AAAGGCTCACCAGGTT']\n",
      "split_fragment_line_string: concatenated_value2   ENCSR618WVK-1_AAAGGCTCACCAGGTT\n",
      "split_fragment_line_string: split_list appbend  ['chr1', '10005', '10406', 'AAAGGCTCACCAGGTT_ENCSR618WVK', 'AAAGGCTCACCAGGTT', 'ENCSR618WVK', '1', 'ENCSR618WVK_AAAGGCTCACCAGGTT', 'ENCSR618WVK-1_AAAGGCTCACCAGGTT']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['chr1',\n",
       " '10005',\n",
       " '10406',\n",
       " 'AAAGGCTCACCAGGTT_ENCSR618WVK',\n",
       " 'AAAGGCTCACCAGGTT',\n",
       " 'ENCSR618WVK',\n",
       " '1',\n",
       " 'ENCSR618WVK_AAAGGCTCACCAGGTT',\n",
       " 'ENCSR618WVK-1_AAAGGCTCACCAGGTT']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# string=\"chr1\t10005\t10406\tAAAGGCTCACCAGGTT_ENCSR618WVK\t1\"\n",
    "# split_fragment_line_string(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5122e73-47fe-4153-bca1-1b121aaaac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_fragment_line_string: string after remove new line chr1\t10005\t10108\tTACCGAAGTCCTTCTC\n",
    "# split_fragment_line_string: split_list  ['chr1', '10005', '10108', 'TACCGAAGTCCTTCTC']\n",
    "# split_fragment_line_string: last_word  10108\n",
    "# split_fragment_line_string: split_word  ['10108']\n",
    "# split_fragment_line_string: split_list insert  ['chr1', '10005', '10108', '10108', 'TACCGAAGTCCTTCTC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7889b2df-9899-43ef-aa7f-c7fd4a9b4b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_fragment_line_string: string after remove new line chr1\t10005\t10406\tAAAGGCTCACCAGGTT_ENCSR618WVK\t1\n",
    "# split_fragment_line_string: split_list  ['chr1', '10005', '10406', 'AAAGGCTCACCAGGTT_ENCSR618WVK', '1']\n",
    "# split_fragment_line_string: last_word  AAAGGCTCACCAGGTT_ENCSR618WVK\n",
    "# split_fragment_line_string: split_word  ['AAAGGCTCACCAGGTT', 'ENCSR618WVK']\n",
    "# split_fragment_line_string: split_list insert  ['chr1', '10005', '10406', 'AAAGGCTCACCAGGTT_ENCSR618WVK', 'AAAGGCTCACCAGGTT', '1']\n",
    "# split_fragment_line_string: split_list insert 2  ['chr1', '10005', '10406', 'AAAGGCTCACCAGGTT_ENCSR618WVK', 'AAAGGCTCACCAGGTT', 'ENCSR618WVK', '1']\n",
    "# split_fragment_line_string: concatenated_value   ENCSR618WVK_AAAGGCTCACCAGGTT\n",
    "# split_fragment_line_string: split_list appbend  ['chr1', '10005', '10406', 'AAAGGCTCACCAGGTT_ENCSR618WVK', 'AAAGGCTCACCAGGTT', 'ENCSR618WVK', '1', 'ENCSR618WVK_AAAGGCTCACCAGGTT']\n",
    "# out_list is ['chr1', '10005', '10406', 'AAAGGCTCACCAGGTT_ENCSR618WVK', 'AAAGGCTCACCAGGTT', 'ENCSR618WVK', '1', 'ENCSR618WVK_AAAGGCTCACCAGGTT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7340bf-dc3f-42de-a0ed-0a4feedaaaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_empty_column_at_position(df, column_name,position):\n",
    "    # Add a new column with empty values\n",
    "#     df[column_name] = \"\"\n",
    "  df.insert(position, column_name, \"\")\n",
    "  return df  # Return the modified DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8218f4cb-198f-457a-8296-c6368a97c0c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
